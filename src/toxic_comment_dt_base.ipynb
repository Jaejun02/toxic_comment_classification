{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"cb6997bd","cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"id":"2d0ba33d","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nrandom = 14 #Fix Random_State\n\nfrom nltk.stem import WordNetLemmatizer # Group Words with Same Form to Same Word\nimport nltk\n## Remove the Comments if they are Not Installed in your Environment.\n## nltk.download('stopwords',quiet=True)\n## nltk.download('wordnet',quiet=True)\n## nltk.download('omw-1.4',quiet=True)\nfrom nltk.corpus import stopwords #Stopwords refers to Words that are going to be Ignored\nimport string\nimport operator\nimport functools\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import balanced_accuracy_score,classification_report,confusion_matrix,f1_score\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T03:09:29.550778Z","iopub.execute_input":"2024-12-26T03:09:29.551238Z","iopub.status.idle":"2024-12-26T03:09:29.854882Z","shell.execute_reply.started":"2024-12-26T03:09:29.551209Z","shell.execute_reply":"2024-12-26T03:09:29.853466Z"}},"outputs":[],"execution_count":4},{"id":"96c15378","cell_type":"markdown","source":"# Import and Preprocess Datasets\n\n1. Read `train.csv` and `test.csv` and combine them into one dataset `D`.\n2. Force the target value into a binary value.\n3. Perform text preprocessing: Lower Casing, Counting number of words etc.\n4. Lemmatizing Strings.\n5. From `D` perform train-test-split to create training and testing dataset. (Step 1 and 5 was done to rearrange the size of 2 datasets.)","metadata":{}},{"id":"e3c74627","cell_type":"code","source":"## Dataset Paths\npath = '../data/'\ntrain_path = f'{path}train.csv'\ntest_path = f'{path}test.csv'\ntest_labels_path = f'{path}test_labels.csv'\n\n## Reading Datasets\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\ntest_labels = pd.read_csv(test_labels_path)[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\ntest = pd.concat([test, test_labels],axis=1)\ntest = test.loc[test['toxic'] != -1] # Labels of value -1 indicates that it was not labelled and cannot be used to derive a test score.\n\nD = pd.concat([train, test], axis=0)\n\n## Create New Dependent Variable - Malignant for D \ndef force_one(x):\n    if x > 1:\n        return 1\n    else:\n        return x\n\nD['malignant'] = D['toxic'] + D['obscene'] + D['threat'] + D['insult'] + D['identity_hate']\nD['malignant'] = D['malignant'].apply(lambda x: force_one(x))\nD = D[['id','comment_text','malignant']] # Forced into binary target.\n\nD.head()\n\n## Text Pre-Processing - D\n\n#### Make Strings to Lower Case\nD['comment_text'] = D['comment_text'].str.lower()\n\n#### Keep Track of String's Original Length\nD['length'] = D['comment_text'].str.len()\n\n#### Replace Email Address with 'email'\nD['comment_text'] = D['comment_text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','email')\n\n#### Replace Website Address with 'website'\nD['comment_text'] = D['comment_text'].str.replace(r'^http[s]{0,1}\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','website')\n\n#### Replace Website Address with 'phonenumber'\nD['comment_text'] = D['comment_text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumber') # Note, might contain a random 10 digit number.\n\n#### Replace Numbers with 'numbr'\nD['comment_text'] = D['comment_text'].str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n\n#### Special Punctuations are Replaced Explicitly.\nD['comment_text'] = D['comment_text'].str.replace(r'!',' exclamationmark')\nD['comment_text'] = D['comment_text'].str.replace(r'\\?',' questionmark')\nD['comment_text'] = D['comment_text'].str.replace(r'\\.{1}',' periodmark')\nD['comment_text'] = D['comment_text'].str.replace(r'\\.{2,}',' ellipsismark')\nD['comment_text'] = D['comment_text'].str.replace(r'Â£|\\$', ' dollers')\n\n## Removing Leftover Punctuations\ndef remove_punct(text):\n    p_free=\"\".join([i for i in text if i not in string.punctuation])\n    return p_free\nstop_words = set(stopwords.words('english'))\n\nD['comment_text'] = D['comment_text'].apply(lambda x:remove_punct(x))\n\nD['comment_text'] = D['comment_text'].apply(lambda x:remove_punct(x))\nD['comment_text'] = D['comment_text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n\nlemmatizer = WordNetLemmatizer()\nD['comment_text'] = D['comment_text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()))\n\nX = D['comment_text']\ny = D['malignant']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7a908610","cell_type":"markdown","source":"Since having an unbalanced dataset might cause the problems such as insufficient learning about lesser target value etc., a balanced dataset was created via undersampling. Since it decreases the data size, it might not help, but it was tried.","metadata":{}},{"id":"7c8a5f19","cell_type":"code","source":"# Prepare balanced dataset obtained via undersampling\nnonmalig = X_train[y_train == 0]\nnonmalig_y = y_train[y_train == 0]\nnum_nonmalig = len(nonmalig)\nmalig = X_train[y_train == 1]\nmalig_y = y_train[y_train == 1]\nnum_malig = len(malig)\n\n#chosen_idx = np.random.choice(num_nonmalig,replace=False,size=num_malig)\nchosen_idx_path = '../data/chosen_idx.csv' # chosen_idx.csv is a list of index that was randomly chosen in prior to effectively undersample the non-malignant data.\nchosen_idx = pd.read_csv(chosen_idx_path)\nchosen_idx = np.array(chosen_idx['0'])\nchosen_nonmalig = nonmalig.iloc[chosen_idx]\nchosen_nonmalig_y = np.array(y_train)[chosen_idx]\n\nX_train_un = pd.concat([chosen_nonmalig, malig],axis=0)\ny_train_un = np.concatenate((chosen_nonmalig_y, malig_y), axis=None)\n\nundersampled_num = len(y_train_un)\n\nmix_idx_path = f'{path}mix_idx.csv'\nmix_idx = pd.read_csv(mix_idx_path)\nmix_idx = np.array(mix_idx['0'])\n\nX_train_un = X_train_un.iloc[mix_idx]\ny_train_un = y_train_un[mix_idx]\n","metadata":{},"outputs":[],"execution_count":3},{"id":"7f44526b","cell_type":"markdown","source":"Vertorizing list of words to train Decision Tree Model using `TfidfVectorizer`.","metadata":{}},{"id":"6dc25300","cell_type":"code","source":"# Changing Words into Vector - Something Like One Hot Encoding\nword_vectorize = TfidfVectorizer(max_features = 20000, stop_words='english')\nX_train = word_vectorize.fit_transform(X_train)\nX_test_copy = X_test.copy()\nX_test = word_vectorize.transform(X_test)\n\nword_vectorize = TfidfVectorizer(max_features = 20000, stop_words='english')\nX_train_un = word_vectorize.fit_transform(X_train_un)\nX_test_un = word_vectorize.transform(X_test_copy)","metadata":{},"outputs":[],"execution_count":4},{"id":"c2ef51ca","cell_type":"markdown","source":"# Training Decision Tree Model for Baseline","metadata":{}},{"id":"ff19d1d9","cell_type":"markdown","source":"## Using Original Unbalanced Dataset","metadata":{}},{"id":"f755a52f","cell_type":"code","source":"# DT for Unbalanced Dataset\n\nclf = DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\nprint(clf.tree_.max_depth) # 3470 -> Therefore, we only have test the depth until 3500 to test regularization effect.\n\nDT = DecisionTreeClassifier(random_state=random)\n\nparams = {\n    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n    'max_depth': [5, 50, 500, 1000, 2000, 3000, 3500, None],\n    'min_samples_split': [2, 10, 20, 50, 100, 1000]\n}\n\ngrid_search = GridSearchCV(estimator=DT,\n                           param_grid=params,\n                           cv=5,\n                           n_jobs=-1,\n                           verbose=10,\n                           scoring=\"f1_macro\")\n\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f68f8143","cell_type":"code","source":"# results = pd.DataFrame(grid_search.cv_results_).sort_values('rank_test_score')\n# results.to_csv('DTresults.csv') # Store the results later reference.","metadata":{},"outputs":[],"execution_count":5},{"id":"3fa49636-bfcb-4721-a6aa-99616437e609","cell_type":"markdown","source":"The best model parameter found by GridSearch for Decision Tree and Unbalanced Dataset is \n* criterion: \"gini\"\n* max_depth = 50\n* min_samples_split = 1000\n\nThe Final Test Score run on test set was:\n* Accuracy: 0.94\n* F1-Macro Score: 0.8156","metadata":{}},{"id":"b26d60fd","cell_type":"code","source":"#results using top parameters (unbalanced)\nprint(grid_search.best_params_)\nclf = grid_search.best_estimator_\nclf.fit(X_train, y_train)\ny_pred_dt = clf.predict(X_test)\nprint('[DT] f1 macro score of Unbalanced Dataset is {}'.format(f1_score(y_test, y_pred_dt, average = 'macro')))\nprint(confusion_matrix(y_test,y_pred_dt))\nprint(classification_report(y_test,y_pred_dt))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"99fa4657","cell_type":"code","source":"cv = 10\nskf = StratifiedKFold(n_splits=cv)\nscores = []\nfor i, (train_index, test_index) in enumerate(skf.split(X_train,y_train)):\n    X_t = X_train[train_index]\n    X_v = X_train[test_index]\n    y_t = y_train.iloc[train_index]\n    y_v = y_train.iloc[test_index]\n    clf = DT = DecisionTreeClassifier(criterion = 'gini', max_depth = 50, min_samples_split = 1000)\n    clf.fit(X_t, y_t)\n    y_pred = clf.predict(X_v)\n    score = f1_score(y_v, y_pred, average = 'macro')\n    scores.append(score)","metadata":{},"outputs":[],"execution_count":null},{"id":"58d4c8a0","cell_type":"code","source":"dt_ori_mean = np.mean(scores)\ndt_ori_std = np.std(scores)\ndt_ori_ci = [dt_ori_mean - 3*dt_ori_std, dt_ori_mean + 3*dt_ori_std] ## Includes 99.7% numbers around est. mean.","metadata":{},"outputs":[],"execution_count":null},{"id":"1166d551","cell_type":"code","source":"print(\"Mean CV Score: {}\".format(dt_ori_mean))\nprint(\"Standard Deviation CV Score: {}\".format(dt_ori_std))\nprint(\"99.7% Confidence Interval: {}\".format(dt_ori_ci))","metadata":{},"outputs":[],"execution_count":null},{"id":"b329d64f","cell_type":"markdown","source":"## Using Undersampled Dataset","metadata":{}},{"id":"f59e6837","cell_type":"code","source":"# DT for Balanced Dataset obtained via undersampling\n\nDT_bal = DecisionTreeClassifier(random_state=87)\n\nparams = {\n    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n    'max_depth': [5, 50, 500, 1000, 2000, 3000, 3500, None],\n    'min_samples_split': [2, 10, 20, 50, 100, 1000]\n}\n\ngrid_search = GridSearchCV(estimator=DT_bal,\n                           param_grid=params,\n                           cv=5,\n                           n_jobs=-1,\n                           verbose=10,\n                           scoring=\"f1_macro\")\n\ngrid_search.fit(X_train_un, y_train_un)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6cdc8f28","cell_type":"code","source":"# results = pd.DataFrame(grid_search.cv_results_).sort_values('rank_test_score')\n# results.to_csv('DTUndersampledResults.csv')","metadata":{},"outputs":[],"execution_count":33},{"id":"9f8c0033-8896-4853-947c-c92a1e77b4e3","cell_type":"markdown","source":"The best model parameter found by GridSearch for Decision Tree and Undersampled Dataset is \n* criterion: \"entropy\"\n* max_depth = 500\n* min_samples_split = 1000,\n\nThe Final Test Score run on test set was:\n* Accuracy: 0.83\n* F1-Macro Score: 0.6909","metadata":{}},{"id":"dc12049f","cell_type":"code","source":"#results using top parameters (undersampled balanced)\nprint(grid_search.best_params_)\nclf = grid_search.best_estimator_\nclf.fit(X_train_un, y_train_un)\ny_bal_pred_dt = clf.predict(X_test)\nprint('[DT] f1 macro score of Undersampled Balanced Dataset is {}'.format(f1_score(y_test, y_bal_pred_dt, average = 'macro')))\nprint(confusion_matrix(y_test,y_bal_pred_dt))\nprint(classification_report(y_test,y_bal_pred_dt))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8180426e","cell_type":"code","source":"cv = 10\nskf = StratifiedKFold(n_splits=cv)\nscores = []\nfor i, (train_index, test_index) in enumerate(skf.split(X_train_un,y_train_un)):\n    X_t = X_train_un[train_index]\n    X_v = X_train_un[test_index]\n    y_t = y_train_un[train_index]\n    y_v = y_train_un[test_index]\n    clf = DecisionTreeClassifier(criterion='entropy', max_depth=500, min_samples_split=1000)\n    clf.fit(X_t, y_t)\n    y_pred = clf.predict(X_v)\n    score = f1_score(y_v, y_pred, average = 'macro')\n    scores.append(score)","metadata":{},"outputs":[],"execution_count":8},{"id":"95df1597","cell_type":"code","source":"dt_un_mean = np.mean(scores)\ndt_un_std = np.std(scores)\ndt_un_ci = [dt_un_mean - 3*dt_un_std, dt_un_mean + 3*dt_un_std] ## Includes 99.7% numbers around est. mean.","metadata":{},"outputs":[],"execution_count":9},{"id":"0c318209","cell_type":"code","source":"print(\"Mean CV Score: {}\".format(dt_un_mean))\nprint(\"Standard Deviation CV Score: {}\".format(dt_un_std))\nprint(\"99.7% Confidence Interval: {}\".format(dt_un_ci))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}